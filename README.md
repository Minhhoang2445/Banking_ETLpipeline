# ğŸ¦ Banking Data Ingestion Platform

> **Mini Data Platform** - Há»‡ thá»‘ng ETL xá»­ lÃ½ dá»¯ liá»‡u ngÃ¢n hÃ ng sá»­ dá»¥ng FastAPI + Apache Airflow + Docker

---

## ğŸ“‹ Giá»›i thiá»‡u dá»± Ã¡n

### Má»¥c Ä‘Ã­ch

ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng **Data Ingestion** cho phÃ©p:

- Upload file dá»¯ liá»‡u ngÃ¢n hÃ ng (Excel/CSV) qua REST API
- Tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i Excel â†’ CSV
- Trigger pipeline xá»­ lÃ½ dá»¯ liá»‡u (ETL) thÃ´ng qua Apache Airflow
- LÆ°u káº¿t quáº£ vÃ o Data Warehouse (PostgreSQL)

### BÃ i toÃ¡n giáº£i quyáº¿t

Trong thá»±c táº¿, dá»¯ liá»‡u khÃ¡ch hÃ ng ngÃ¢n hÃ ng thÆ°á»ng Ä‘Æ°á»£c xuáº¥t tá»« cÃ¡c há»‡ thá»‘ng legacy dÆ°á»›i dáº¡ng Excel/CSV. Dá»± Ã¡n nÃ y giáº£i quyáº¿t bÃ i toÃ¡n:

| Váº¥n Ä‘á»                         | Giáº£i phÃ¡p                                                       |
| ------------------------------ | --------------------------------------------------------------- |
| Xá»­ lÃ½ thá»§ cÃ´ng file Excel/CSV  | API tá»± Ä‘á»™ng nháº­n vÃ  xá»­ lÃ½ file                                  |
| KhÃ´ng cÃ³ quy trÃ¬nh ETL rÃµ rÃ ng | Airflow DAG vá»›i cÃ¡c bÆ°á»›c: Validate â†’ Extract â†’ Transform â†’ Load |
| TrÃ¹ng láº·p dá»¯ liá»‡u              | Hash file Ä‘á»ƒ phÃ¡t hiá»‡n file Ä‘Ã£ upload                           |
| KhÃ³ triá»ƒn khai mÃ´i trÆ°á»ng      | Docker Compose má»™t bÆ°á»›c                                         |

---

## ğŸ—ï¸ Kiáº¿n trÃºc tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client       â”‚    â”‚   FastAPI       â”‚    â”‚   Apache Airflow â”‚
â”‚  (Upload file) â”‚â”€â”€â”€â–¶â”‚  Ingestion API  â”‚â”€â”€â”€â–¶â”‚   ETL Pipeline   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚                        â”‚
                             â–¼                        â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ /data folderâ”‚         â”‚  PostgreSQL  â”‚
                      â”‚ (CSV files) â”‚         â”‚  Data Warehouseâ”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ThÃ nh pháº§n chÃ­nh

| Component          | MÃ´ táº£                                                            |
| ------------------ | ---------------------------------------------------------------- |
| **FastAPI**        | REST API nháº­n file upload, chuyá»ƒn Ä‘á»•i Excelâ†’CSV, trigger Airflow |
| **Apache Airflow** | Äiá»u phá»‘i vÃ  thá»±c thi pipeline ETL                               |
| **PostgreSQL**     | Database cho Airflow metadata + Data Warehouse                   |
| **Docker Compose** | ÄÃ³ng gÃ³i vÃ  cháº¡y toÃ n bá»™ há»‡ thá»‘ng                                |

---

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

### Cháº¡y báº±ng Docker (khuyáº¿n nghá»‹)

- **Docker Desktop**: phiÃªn báº£n 20.x trá»Ÿ lÃªn
- **Docker Compose**: phiÃªn báº£n 2.x trá»Ÿ lÃªn
- **RAM**: tá»‘i thiá»ƒu 4GB
- **Disk**: tá»‘i thiá»ƒu 2GB trá»‘ng

### Cháº¡y local (khÃ´ng Docker)

- **Python**: 3.9 - 3.11
- **PostgreSQL**: 13.x trá»Ÿ lÃªn
- **pip**: phiÃªn báº£n má»›i nháº¥t

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
FinalProject/
â”œâ”€â”€ ğŸ“‚ ingestion_api/          # FastAPI Application
â”‚   â”œâ”€â”€ main.py                # Entry point cá»§a API
â”‚   â”œâ”€â”€ routers/               # API endpoints
â”‚   â”‚   â””â”€â”€ ingest.py          # Endpoint upload file
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â”‚   â””â”€â”€ file_ingest_service.py
â”‚   â””â”€â”€ schemas/               # Pydantic schemas
â”‚       â””â”€â”€ ingest_response.py
â”‚
â”œâ”€â”€ ğŸ“‚ dags/                   # Airflow DAGs
â”‚   â””â”€â”€ banking_campaign_analysis_dag.py  # Pipeline ETL chÃ­nh
â”‚
â”œâ”€â”€ ğŸ“‚ plugins/                # Airflow custom operators & helpers
â”‚   â”œâ”€â”€ extract.py             # TrÃ­ch xuáº¥t dá»¯ liá»‡u
â”‚   â”œâ”€â”€ transform.py           # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u
â”‚   â”œâ”€â”€ load.py                # Load vÃ o Data Warehouse
â”‚   â”œâ”€â”€ validateFile.py        # Validate file (hash check)
â”‚   â”œâ”€â”€ validateData.py        # Validate dá»¯ liá»‡u
â”‚   â””â”€â”€ prepareStaging.py      # Chuáº©n bá»‹ báº£ng staging
â”‚
â”œâ”€â”€ ğŸ“‚ data/                   # ThÆ° má»¥c chá»©a file CSV Ä‘Ã£ upload
â”œâ”€â”€ ğŸ“‚ logs/                   # Airflow logs
â”œâ”€â”€ ğŸ“‚ scripts/                # Scripts há»— trá»£
â”‚
â”œâ”€â”€ docker-compose.yaml        # Cáº¥u hÃ¬nh Docker services
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # Biáº¿n mÃ´i trÆ°á»ng
â””â”€â”€ README.md                  # TÃ i liá»‡u nÃ y
```

---

## ğŸ³ HÆ°á»›ng dáº«n cháº¡y báº±ng Docker

### BÆ°á»›c 1: Clone source code

```bash
git clone <repository-url>
cd FinalProject
```

### BÆ°á»›c 2: Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

Kiá»ƒm tra file `.env` vÃ  cáº­p nháº­t náº¿u cáº§n:

```env
AIRFLOW_UID=50000
```

### BÆ°á»›c 3: Khá»Ÿi táº¡o Airflow vÃ  cháº¡y cÃ¡c services

```bash
# Khá»Ÿi cháº¡y toÃ n bá»™ há»‡ thá»‘ng
docker-compose up -d

# Xem logs (optional)
docker-compose logs -f
```

> â±ï¸ **Láº§n Ä‘áº§u cháº¡y sáº½ máº¥t 2-3 phÃºt** Ä‘á»ƒ Airflow khá»Ÿi táº¡o database vÃ  táº¡o user admin.

### BÆ°á»›c 4: Khá»Ÿi cháº¡y FastAPI (cháº¡y riÃªng trÃªn host)

```bash
# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Cháº¡y FastAPI
cd ingestion_api
python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### BÆ°á»›c 5: Truy cáº­p cÃ¡c services

| Service                  | URL                        | Credentials       |
| ------------------------ | -------------------------- | ----------------- |
| **FastAPI Docs**         | http://localhost:8000/docs | -                 |
| **Airflow Web UI**       | http://localhost:8080      | admin / admin     |
| **PostgreSQL (Airflow)** | localhost:5434             | airflow / airflow |

### Dá»«ng há»‡ thá»‘ng

```bash
docker-compose down

# XÃ³a cáº£ volumes (reset data)
docker-compose down -v
```

---

## ğŸ–¥ï¸ HÆ°á»›ng dáº«n cháº¡y Local (khÃ´ng Docker)

### BÆ°á»›c 1: Táº¡o Virtual Environment

```bash
# Táº¡o virtualenv
python -m venv venv

# KÃ­ch hoáº¡t (Windows)
.\venv\Scripts\activate

# KÃ­ch hoáº¡t (Linux/Mac)
source venv/bin/activate
```

### BÆ°á»›c 2: CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### BÆ°á»›c 3: Cáº¥u hÃ¬nh Airflow (náº¿u cháº¡y local)

```bash
# Thiáº¿t láº­p AIRFLOW_HOME
export AIRFLOW_HOME=$(pwd)

# Khá»Ÿi táº¡o database
airflow db init

# Táº¡o user admin
airflow users create \
    --username admin \
    --password admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com
```

### BÆ°á»›c 4: Cháº¡y FastAPI

```bash
cd ingestion_api
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### BÆ°á»›c 5: Cháº¡y Airflow (2 terminal riÃªng)

```bash
# Terminal 1: Webserver
airflow webserver --port 8080

# Terminal 2: Scheduler
airflow scheduler
```

---

## ğŸ“¡ CÃ¡ch sá»­ dá»¥ng API

### Endpoint Upload File

| Method | Endpoint       | MÃ´ táº£                          |
| ------ | -------------- | ------------------------------ |
| `POST` | `/ingest/file` | Upload file Excel/CSV Ä‘á»ƒ xá»­ lÃ½ |

### VÃ­ dá»¥ Request báº±ng cURL

**Upload file CSV:**

```bash
curl -X POST "http://localhost:8000/ingest/file" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@banking_data.csv"
```

**Upload file Excel (.xlsx):**

```bash
curl -X POST "http://localhost:8000/ingest/file" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@banking_data.xlsx"
```

### Response thÃ nh cÃ´ng

```json
{
  "message": "File ingested successfully (standardized to CSV)",
  "csv_path": "/opt/airflow/data/banking_20250201_174500.csv"
}
```

### Sá»­ dá»¥ng Swagger UI

1. Truy cáº­p http://localhost:8000/docs
2. Chá»n endpoint `POST /ingest/file`
3. Click **Try it out**
4. Chá»n file vÃ  click **Execute**

---

## ğŸ”„ Luá»“ng xá»­ lÃ½ dá»¯ liá»‡u

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LUá»’NG Xá»¬ LÃ Dá»® LIá»†U                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1. UPLOAD FILE                                                          â”‚
â”‚     â””â”€â–¶ Client gá»­i file Excel/CSV Ä‘áº¿n API /ingest/file                   â”‚
â”‚                                                                          â”‚
â”‚  2. LÆ¯U FILE Táº M                                                         â”‚
â”‚     â””â”€â–¶ FastAPI lÆ°u file vÃ o thÆ° má»¥c táº¡m (tempfile)                      â”‚
â”‚                                                                          â”‚
â”‚  3. CONVERT EXCEL â†’ CSV (náº¿u cáº§n)                                        â”‚
â”‚     â””â”€â–¶ Sá»­ dá»¥ng pandas Ä‘á»ƒ chuyá»ƒn Ä‘á»•i .xlsx â†’ .csv                        â”‚
â”‚     â””â”€â–¶ LÆ°u CSV vÃ o thÆ° má»¥c /data vá»›i timestamp                          â”‚
â”‚                                                                          â”‚
â”‚  4. TRIGGER AIRFLOW DAG                                                  â”‚
â”‚     â””â”€â–¶ Gá»i Airflow REST API Ä‘á»ƒ cháº¡y DAG: banking_etl_pipeline           â”‚
â”‚     â””â”€â–¶ Truyá»n csv_path qua dag_run.conf                                 â”‚
â”‚                                                                          â”‚
â”‚  5. AIRFLOW PIPELINE (DAG)                                               â”‚
â”‚     â”œâ”€â–¶ validate_file: Hash file Ä‘á»ƒ kiá»ƒm tra trÃ¹ng láº·p                   â”‚
â”‚     â”œâ”€â–¶ prepare_staging: Táº¡o/reset báº£ng staging                          â”‚
â”‚     â”œâ”€â–¶ extract: Äá»c CSV vÃ  load vÃ o staging table                       â”‚
â”‚     â”œâ”€â–¶ transform: Chuyá»ƒn Ä‘á»•i vÃ  lÃ m sáº¡ch dá»¯ liá»‡u                        â”‚
â”‚     â”œâ”€â–¶ validate_data: Validate dá»¯ liá»‡u Ä‘Ã£ transform                     â”‚
â”‚     â””â”€â–¶ load: LÆ°u vÃ o Data Warehouse vÃ  Ä‘Ã¡nh dáº¥u processed               â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Chi tiáº¿t cÃ¡c bÆ°á»›c trong Airflow DAG

| Task              | MÃ´ táº£                                                  | File                |
| ----------------- | ------------------------------------------------------ | ------------------- |
| `validate_file`   | TÃ­nh SHA256 hash cá»§a file, kiá»ƒm tra trÃ¹ng láº·p trong DB | `validateFile.py`   |
| `prepare_staging` | Táº¡o báº£ng staging náº¿u chÆ°a cÃ³                           | `prepareStaging.py` |
| `extract`         | Äá»c CSV vÃ  insert vÃ o staging table                    | `extract.py`        |
| `transform`       | LÃ m sáº¡ch, chuáº©n hÃ³a dá»¯ liá»‡u                            | `transform.py`      |
| `validate_data`   | Kiá»ƒm tra cháº¥t lÆ°á»£ng dá»¯ liá»‡u                            | `validateData.py`   |
| `load`            | Load vÃ o báº£ng chÃ­nh trong Data Warehouse               | `load.py`           |

---

## âš™ï¸ Cáº¥u hÃ¬nh

### Biáº¿n mÃ´i trÆ°á»ng quan trá»ng

| Biáº¿n                      | MÃ´ táº£                                | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh                                                          |
| ------------------------- | ------------------------------------ | ------------------------------------------------------------------------- |
| `AIRFLOW_UID`             | User ID cho Airflow container        | `50000`                                                                   |
| `DW_CONN_STRING`          | Connection string Ä‘áº¿n Data Warehouse | `postgresql+psycopg2://postgres:123456@host.docker.internal:5433/Banking` |
| `AIRFLOW__CORE__EXECUTOR` | Executor type                        | `LocalExecutor`                                                           |

### Airflow API Credentials

```python
AIRFLOW_URL = "http://localhost:8080"
AIRFLOW_USER = "admin"
AIRFLOW_PASS = "admin"
```

---

## ğŸ“ Ghi chÃº & HÆ°á»›ng phÃ¡t triá»ƒn

### âœ… TÃ­nh nÄƒng Ä‘Ã£ cÃ³

- [x] Upload file CSV/Excel qua API
- [x] Tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i Excel â†’ CSV
- [x] Trigger Airflow DAG tá»± Ä‘á»™ng
- [x] Hash file Ä‘á»ƒ chá»‘ng trÃ¹ng láº·p (SHA256)
- [x] ETL Pipeline hoÃ n chá»‰nh

### ğŸš€ HÆ°á»›ng phÃ¡t triá»ƒn tiáº¿p

- [ ] **Validate file nÃ¢ng cao**: Kiá»ƒm tra schema, data types trÆ°á»›c khi xá»­ lÃ½
- [ ] **Deduplication thÃ´ng minh**: So sÃ¡nh hash theo tá»«ng row, khÃ´ng chá»‰ file
- [ ] **Monitoring & Alerting**: TÃ­ch há»£p Prometheus + Grafana
- [ ] **Logging táº­p trung**: Sá»­ dá»¥ng ELK Stack (Elasticsearch, Logstash, Kibana)
- [ ] **Scale horizontal**: Sá»­ dá»¥ng CeleryExecutor vá»›i Redis/RabbitMQ
- [ ] **Authentication**: ThÃªm JWT authentication cho API
- [ ] **Rate limiting**: Giá»›i háº¡n sá»‘ request Ä‘á»ƒ báº£o vá»‡ há»‡ thá»‘ng
- [ ] **Retry mechanism**: Tá»± Ä‘á»™ng retry khi task tháº¥t báº¡i

### ğŸ› Troubleshooting

| Lá»—i                               | NguyÃªn nhÃ¢n                 | Giáº£i phÃ¡p                                                 |
| --------------------------------- | --------------------------- | --------------------------------------------------------- |
| Airflow Web UI khÃ´ng load         | Database chÆ°a khá»Ÿi táº¡o xong | Äá»£i 2-3 phÃºt hoáº·c cháº¡y `docker-compose logs airflow-init` |
| Upload file lá»—i 500               | Airflow chÆ°a sáºµn sÃ ng       | Kiá»ƒm tra Airflow Ä‘ang cháº¡y vÃ  DAG Ä‘Ã£ unpause              |
| File Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ trÆ°á»›c Ä‘Ã³       | Hash trÃ¹ng láº·p              | ÄÃ¢y lÃ  tÃ­nh nÄƒng chá»‘ng duplicate, upload file khÃ¡c        |
| KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Data Warehouse | Connection string sai       | Kiá»ƒm tra `DW_CONN_STRING` trong docker-compose.yaml       |

---

## ğŸ‘¥ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh! Vui lÃ²ng:

1. Fork repository
2. Táº¡o branch má»›i (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Má»Ÿ Pull Request

---

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch há»c táº­p.

---

<p align="center">
  <b>Made with â¤ï¸ for Data Engineering Learning</b>
</p>
